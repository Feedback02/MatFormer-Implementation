{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqmtGGA_tNjq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class NestedFFN(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, num_granularities=4):\n",
        "        super(NestedFFN, self).__init__()\n",
        "\n",
        "        # Initialize FFN layers\n",
        "        self.num_granularities = num_granularities\n",
        "        self.d_model = d_model\n",
        "        self.d_ff = d_ff\n",
        "\n",
        "        # Create weight matrices for W1 and W2 with the largest size\n",
        "        self.W1 = nn.Parameter(torch.randn(d_ff, d_model))\n",
        "        self.W2 = nn.Parameter(torch.randn(d_ff, d_model))\n",
        "\n",
        "        # Calculate the sizes of each granularity\n",
        "        self.granularity_sizes = [d_ff // (2 ** i) for i in range(num_granularities)]\n",
        "        print(self.granularity_sizes)\n",
        "\n",
        "    def forward(self, x, granularity_level):\n",
        "        assert 0 <= granularity_level < self.num_granularities, \"Invalid granularity level\"\n",
        "\n",
        "        # m_i Number of neuron selected\n",
        "        m_i = self.granularity_sizes[granularity_level]\n",
        "\n",
        "        # Perform the FFN operation with the selected subset of weights\n",
        "        hidden = F.gelu(x @ self.W1[:m_i, :].T)\n",
        "        output = hidden @ self.W2[:m_i, :]\n",
        "\n",
        "        return output\n",
        "\n",
        "class TransformerLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, nested_ffn, granularity_level, dropout=0.1):\n",
        "        super(TransformerLayer, self).__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, num_heads, dropout=dropout)\n",
        "        self.granularity_level = granularity_level\n",
        "        self.nested_ffn = nested_ffn\n",
        "        self.layernorm1 = nn.LayerNorm(d_model)\n",
        "        self.layernorm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
        "        src2, _ = self.self_attn(src, src, src, attn_mask=src_mask, key_padding_mask=src_key_padding_mask)\n",
        "        src = src + self.dropout(src2)\n",
        "        src = self.layernorm1(src)\n",
        "\n",
        "        src2 = self.nested_ffn(src, self.granularity_level)\n",
        "        src = src + self.dropout(src2)\n",
        "        src = self.layernorm2(src)\n",
        "\n",
        "        return src\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, d_model, num_layers, num_heads, nested_ffn, num_granularities=4, dropout=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.models = [ ]\n",
        "\n",
        "        # We Stack l Layers with the same granularity_level\n",
        "        # Creating M1, M2, ... , Mg\n",
        "        for id in range(num_granularities):\n",
        "\n",
        "          self.models.append( nn.ModuleList([\n",
        "            TransformerLayer(d_model, num_heads, nested_ffn, id, dropout)\n",
        "            for _ in range(num_layers)\n",
        "          ]))\n",
        "\n",
        "        self.layernorm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, src, src_mask=None, src_key_padding_mask=None, granularity_level = 0):\n",
        "      # So granularity_level indicates the model M_i that we want to use\n",
        "        for layer in self.models[granularity_level]:\n",
        "            src = layer(src, src_mask, src_key_padding_mask)\n",
        "        src = self.layernorm(src)\n",
        "        return src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TY7PeeZ14Bw",
        "outputId": "e66e053e-e4a8-495b-eace-acdb8b387835"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2048, 1024, 512, 256]\n",
            "Epoch 1/10, Loss: 1.8654756820201874\n",
            "Epoch 2/10, Loss: 1.6407215428352355\n",
            "Epoch 3/10, Loss: 1.4758982849121094\n",
            "Epoch 4/10, Loss: 1.3556608510017396\n",
            "Epoch 5/10, Loss: 1.268385728597641\n",
            "Epoch 6/10, Loss: 1.2044523561000824\n",
            "Epoch 7/10, Loss: 1.1572381377220153\n",
            "Epoch 8/10, Loss: 1.1219669103622436\n",
            "Epoch 9/10, Loss: 1.095331188440323\n",
            "Epoch 10/10, Loss: 1.0746522784233092\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "d_model = 512\n",
        "d_ff = 2048\n",
        "num_granularities = 4\n",
        "num_layers = 6\n",
        "num_heads = 8\n",
        "dropout = 0.1\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "sequence_length = 10\n",
        "num_batches = 100\n",
        "inputs = [torch.randn(sequence_length, batch_size, d_model) for _ in range(num_batches)]\n",
        "targets = [torch.randn(sequence_length, batch_size, d_model) for _ in range(num_batches)]\n",
        "\n",
        "# Initialize the model\n",
        "nested_ffn = NestedFFN(d_model, d_ff, num_granularities)\n",
        "model = Transformer(d_model, num_layers, num_heads, nested_ffn, num_granularities=num_granularities, dropout=dropout)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "    for batch_idx in range(num_batches):\n",
        "        input_batch = inputs[batch_idx]\n",
        "        target_batch = targets[batch_idx]\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Compute the loss for each granularity level and combine them\n",
        "        losses = []\n",
        "        for granularity_level in range(num_granularities):\n",
        "            output = model(input_batch, granularity_level=granularity_level)\n",
        "            loss = criterion(output, target_batch)\n",
        "            losses.append(loss)\n",
        "\n",
        "        # Combine the losses\n",
        "        combined_loss = sum(losses) / num_granularities\n",
        "\n",
        "        # Backpropagation\n",
        "        combined_loss.backward()\n",
        "\n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate loss for reporting\n",
        "        total_loss += combined_loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/num_batches}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1r7bu4R3tV6Q"
      },
      "outputs": [],
      "source": [
        "# Output Nodes\n",
        "d_model = 512\n",
        "# Input Nodes\n",
        "d_ff = 2048\n",
        "num_granularities = 4\n",
        "#Number of transformers for each granularity_level ( l of the paper )\n",
        "num_layers = 2\n",
        "num_heads = 8\n",
        "granularity_level = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJaCW0NdtT9y",
        "outputId": "e9a32126-bb6a-4609-910d-16d903f3502c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2048, 1024, 512, 256]\n",
            "2048\n",
            "2048\n",
            "torch.Size([10, 32, 512])\n"
          ]
        }
      ],
      "source": [
        "nested_ffn = NestedFFN(d_model, d_ff, num_granularities)\n",
        "\n",
        "transformer = Transformer(d_model, num_layers, num_heads, nested_ffn, granularity_level)\n",
        "\n",
        "x = torch.randn(10, 32, d_model)  # sequence length 10, batch size 32, d_model 512\n",
        "\n",
        "output = transformer(x)\n",
        "\n",
        "print(output.shape)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}